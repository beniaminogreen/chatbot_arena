---
title: "Final Report"
author: "Ivan Sinyavin and Ben Green"
date: "2025-12-02"
output: pdf_document
---

```{r, echo = F, message = F, include = F}
library(arrow)
library(tidyverse)
library(knitr)
library(dplyr)

opts_chunk$set(cache=TRUE)

files <- c(
   "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00000-of-00007.parquet",
   "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00001-of-00007.parquet",
  "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00002-of-00007.parquet",
   "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00003-of-00007.parquet",
   "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00004-of-00007.parquet",
 "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00005-of-00007.parquet",
"/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00006-of-00007.parquet"
 )

#files <- list.files(pattern="*.parquet")

x <- open_dataset(files) %>% 
  select(id, model_a, model_b, winner, category_tag) %>% 
  as.data.frame()

# dim(x)
# head(x[, 1:4])
saveRDS(x, file = 'chatbot.data.rds')
rm(list = ls())
x <- readRDS(file = 'chatbot.data.rds')
# dim(x)
# head(x[, 1:4])
```

# Simple Win/Loss Bradley Terry Model

We start simple. Only looking at win, loss outcomes, we fit a simple Bradley Terry model, which assigns each model $j$ an underlying ability parameter $\lambda_j$. When two models $i$ and $j$ are compared, the model assumes

$$
P(i \text{ beats } j)
=
\frac{\exp(\lambda_i)}{\exp(\lambda_i) + \exp(\lambda_j)}
=
\operatorname{logit}^{-1}(\lambda_i - \lambda_j).
$$

In this model, the probability of one opponent beating another are determined
entirely by the difference in their unobserved abilities. A higher $\lambda_i$
makes model $i$ more likely to win against any opponent. 

This model can be estimated using a GLM with a bespoke predictor matrix $X_{\text{reduced}}$, which has one row for each obervation in our dataset, and $m-1$ columns, where $m$ is the number of models in our dataset. 

We construct $X_{\text{reduced}}$ by first creating a $m \times n$ matrix $X$, which is definied entrywise as: 

$$
X_(i,j)=
\begin{cases}
  1 \quad \text{if model j is the first player in round i}\\
  -1 \quad \text{if model j is the second player in round i}\\
  0\quad \text{otherwise}
\end{cases}
$$

We then remove the first column of $X$ for identifiability to obtain
$X_{\text{reduced}}$. With the predictor matrix created, we can then estimate
the Bradley-Terry model we estimate the ability parameters using a glm with a
logistic link function, where the outcome is modeled as $y_i \sim
\text{Bernoulli}(p_i)$ where $\text{logit}(p_i) = X_{i} \, \beta.$ The
estimated coefficients $\hat\beta$ are the abilities: $\hat\lambda_1 = 0,$
$\hat\lambda_j = \hat\beta_{j-1}$.


```{r}
x_bt <- x %>%
  filter(winner %in% c("model_a", "model_b"), model_a != model_b) %>%
  mutate(y = ifelse(winner == "model_a", 1, 0))  

players <- sort(unique(c(x_bt$model_a, x_bt$model_b)))
J <- length(players)
X <- matrix(0, nrow = nrow(x_bt), ncol = J,
            dimnames = list(NULL, players))
for (i in seq_len(nrow(x_bt))) {
  p1 <- x_bt$model_a[i]
  p2 <- x_bt$model_b[i]
  X[i, p1] <- 1
  X[i, p2] <- -1
}
X_reduced <- X[, -1, drop = FALSE]
colnames(X_reduced) <- paste0("abil_", players[-1])
bt_df <- cbind(y = x_bt$y, as.data.frame(X_reduced))
bt_glm <- glm(y ~ . - 1, data = bt_df, family = binomial())
##summary(bt_glm)

```

We assemble a table containing each model’s estimated ability, its standard error, and its confidence interval. The models are sorted by decreasing ability, which serves a rank. This produces the final Bradley--Terry leaderboard.

```{r}
beta_hat <- coef(bt_glm)               
abilities <- c(0, unname(beta_hat))     
names(abilities) <- players

V_beta <- vcov(bt_glm)

V_full <- matrix(0, nrow = J, ncol = J)
V_full[-1, -1] <- V_beta
colnames(V_full) <- rownames(V_full) <- players

se_abilities <- sqrt(diag(V_full))
z_crit <- 1.96

leaderboard <- tibble(model   = players, ability = abilities, `s.e.` = se_abilities,
  lwr = ability - z_crit * `s.e.`, upr = ability + z_crit * `s.e.`
) %>%
  arrange(desc(ability)) %>%
  mutate(rank = row_number()) %>%
  select(rank, model, ability, `s.e.`, lwr, upr)

print(leaderboard, n = 20)

```

```{r, figure.width=10, fig.height=10}

players_ordered_full <- leaderboard %>%
  arrange(desc(ability)) %>%
  pull(model)

top5    <- head(players_ordered_full, 5)  
bottom5 <- tail(players_ordered_full, 5)   

sub_players   <- c(top5, bottom5) |> unique()
row_col_order <- players_ordered_full[players_ordered_full %in% sub_players]

big_grid_sub <- big_grid %>%
  filter(row_model %in% row_col_order,
         col_model %in% row_col_order)

big_grid_plot_sub <- big_grid_sub %>%
  mutate(
    row_idx = match(row_model, row_col_order),
    col_idx = match(col_model, row_col_order),

    sub_row = case_when(
      outcome %in% c("p_left_wins", "p_top_wins") ~ 1L,  
      TRUE                                         ~ 2L   
    ),
    sub_col = case_when(
      outcome %in% c("p_left_wins", "p_tie") ~ 1L,       
      TRUE                                   ~ 2L       
    ),
    x = (col_idx - 1) * 2 + sub_col,
    y = (row_idx - 1) * 2 + sub_row,

    outcome_label = case_when(
      outcome == "p_top_wins"   ~ "Top wins",
      outcome == "p_left_wins"  ~ "Left wins",
      outcome == "p_tie"        ~ "Tie",
      outcome == "p_both_lose"  ~ "Both lose"
    )
  )

J_sub <- length(row_col_order)

ggplot(big_grid_plot_sub, aes(x = x, y = y, fill = prob)) +
  geom_tile(color = "white", linewidth = 0.1) +
  geom_text(aes(label = sprintf("%.2f", prob)), size = 2) +
  coord_fixed() +
scale_fill_gradientn(
  colours = c("grey85", "yellow", "red"),
  values = scales::rescale(c(0, 0.5, 1))
)+
  scale_x_continuous(
    breaks = (2 * (1:J_sub)) - 0.5,
    labels = row_col_order,
    expand = c(0, 0)
  ) +
  scale_y_reverse(
    breaks = (2 * (1:J_sub)) - 0.5,
    labels = row_col_order,
    expand = c(0, 0)
  ) +
  labs(
    x = "Models (columns, top 5 + bottom 5)",
    y = "Models (rows, top 5 + bottom 5)",
    fill = "Probability",
    title = "Bradley–Terry pairwise probabilities (top 5 and bottom 5 models)",
    subtitle = "Each matchup cell is a 2×2 grid: TL=left model wins, TR=bottom wins, BL=tie, BR=both lose (0 in simple BT)."
  ) +
  theme_minimal(base_size = 9) +
  theme(
    panel.grid = element_blank(),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    plot.title = element_text(face = "bold")
  )


```


# Multinomial Regression Model 

After fitting the Bradley-Terry model, we begin trying to create predictions
for the probability of tying and the 'both bad outcomes' via multinomial
regressions. In these models, we treat each possible outcome matchup---$A$ win, $B$ win, tie, or both\_bad---as its own binary event. For each outcome $k \in \{\text{A},\text{B},\text{tie},\text{bad}\}$ we fit a logistic model 

$$
\text{logit}\big( P(y_k = 1 \mid \text{models } i,j) \big)
= \beta^{(k)}_0 + \beta^{(k)}_i - \beta^{(k)}_j.
$$

Each set of parameters $\beta^{(k)}$ describes how strong each model is with
respect to outcome $k$. For example, large $\beta^{(A)}_i$ means model $i$
tends to produce $A$ wins, large $\beta^{(\text{tie})}_i$ means model $i$ tends to generate ties, and so on. 

When we pair two models $(i,j)$, each logistic regression produces a linear predictor

$$
\eta_k = \widehat{\beta}^{(k)}_0 + \widehat{\beta}^{(k)}_i - \widehat{\beta}^{(k)}_j,
\qquad k \in \{\text{A},\text{B},\text{tie},\text{bad}\}.
$$

To convert these four logits into a valid probability distribution over outcomes, we exponentiate and normalize:

$$
p_k = \frac{e^{\eta_k}}
           {e^{\eta_A} + e^{\eta_B} + e^{\eta_{\rm tie}} + e^{\eta_{\rm bad}}},
\qquad k \in \{\text{A},\text{B},\text{tie},\text{bad}\}.
$$

These probabilities satisfy $p_A + p_B + p_{\rm tie} + p_{\rm bad} = 1,$ so for every ordered matchup $(i,j)$ the model returns a full probability distribution over the four possible outcomes.


```{r}
x_mn <- x %>%
  filter(model_a != model_b) %>%
  mutate(
    outcome = case_when(winner == "model_a" ~ "A_win", winner == "model_b" ~ "B_win", winner == "tie" ~ "tie", winner == "both_bad" ~ "both_bad")
  ) %>%
  filter(!is.na(outcome))

players <- sort(unique(c(x_mn$model_a, x_mn$model_b)))

x_mn <- x_mn %>%
  mutate(player1 = factor(model_a, levels = players), player2 = factor(model_b, levels = players))

X1 <- model.matrix(~ player1 - 1, data = x_mn)
X2 <- model.matrix(~ player2 - 1, data = x_mn)
Z  <- X1 - X2

Z  <- Z[, -1, drop = FALSE]
colnames(Z) <- paste0("theta_", players[-1])

df <- as.data.frame(Z)
df$outcome <- factor(df$outcome <- x_mn$outcome, levels = c("A_win", "B_win", "tie", "both_bad"))

y_A    <- as.integer(df$outcome == "A_win")
y_B    <- as.integer(df$outcome == "B_win")
y_Tie  <- as.integer(df$outcome == "tie")
y_BBad <- as.integer(df$outcome == "both_bad")

predictors_df <- transform(df, outcome = NULL)

fit_A    <- glm(y_A ~ ., data = predictors_df, family = binomial())
fit_B    <- glm(y_B ~ ., data = predictors_df, family = binomial())
fit_Tie  <- glm(y_Tie ~ ., data = predictors_df, family = binomial())
fit_BBad <- glm(y_BBad ~ ., data = predictors_df, family = binomial())

#summary(fit_A); summary(fit_B); summary(fit_Tie); summary(fit_BBad)

make_Z_row <- function(p1, p2, players) {
  v1 <- rep(0, length(players)); v2 <- rep(0, length(players))
  names(v1) <- names(v2) <- players
  v1[p1] <-  1
  v2[p2] <- -1
  z <- v1 + v2           
  z_reduced <- z[-1]    
  names(z_reduced) <- paste0("theta_", players[-1])
  as.data.frame(t(z_reduced))
}

all_pairs <- expand.grid(player1 = players, player2 = players,
                         stringsAsFactors = FALSE) %>%filter(player1 != player2)

Z_new <- do.call(rbind, lapply(seq_len(nrow(all_pairs)), function(k) {
                   make_Z_row(all_pairs$player1[k], all_pairs$player2[k], players)}))

eta_A_new    <- predict(fit_A,    newdata = Z_new, type = "link")
eta_B_new    <- predict(fit_B,    newdata = Z_new, type = "link")
eta_Tie_new  <- predict(fit_Tie,  newdata = Z_new, type = "link")
eta_BBad_new <- predict(fit_BBad, newdata = Z_new, type = "link")

denom <- exp(eta_A_new) + exp(eta_B_new) + exp(eta_Tie_new) + exp(eta_BBad_new)

p_A_new <- exp(eta_A_new) / denom
p_B_new <- exp(eta_B_new) / denom
p_Tie_new  <- exp(eta_Tie_new) / denom
p_BBad_new <- exp(eta_BBad_new)/ denom

```


```{r}
matchups_full <- tibble(
  player1 = all_pairs$player1,
  player2 = all_pairs$player2,
  p_A_win    = p_A_new,
  p_B_win    = p_B_new,
  p_Tie      = p_Tie_new,
  p_BothBad  = p_BBad_new
)

```

```{r, figure.width=10, fig.height=10}

players_ordered_full <- leaderboard %>%
  arrange(desc(ability)) %>%
  pull(model)

top5    <- head(players_ordered_full, 5)   
bottom5 <- tail(players_ordered_full, 5)  

sub_players   <- c(top5, bottom5) |> unique()
row_col_order <- players_ordered_full[players_ordered_full %in% sub_players]

pair_grid_mn <- expand.grid(
  row_model = row_col_order,
  col_model = row_col_order,
  stringsAsFactors = FALSE,
  KEEP.OUT.ATTRS = FALSE
) %>%
  filter(row_model != col_model) %>%
  left_join(
    matchups_full,
    by = c("row_model" = "player1", "col_model" = "player2")
  )

big_grid_mn <- pair_grid_mn %>%
  mutate(
    p_left_win = p_A_win,
    p_top_win  = p_B_win,
    p_tie      = p_Tie,
    p_bad      = p_BothBad
  ) %>%
  pivot_longer(
    cols = c(p_left_win, p_top_win, p_tie, p_bad),
    names_to = "outcome",
    values_to = "prob"
  ) %>%
  mutate(
    sub_row = case_when(
      outcome %in% c("p_left_win", "p_top_win") ~ 1L,  # top row
      TRUE                                      ~ 2L    # bottom row
    ),
    sub_col = case_when(
      outcome %in% c("p_left_win", "p_tie") ~ 1L,       # left col
      TRUE                                  ~ 2L        # right col
    ),
    row_idx = match(row_model, row_col_order),
    col_idx = match(col_model, row_col_order),
    x = (col_idx - 1) * 2 + sub_col,
    y = (row_idx - 1) * 2 + sub_row
  )

J_sub <- length(row_col_order)

ggplot(big_grid_mn, aes(x = x, y = y, fill = prob)) +
  geom_tile(color = "white", linewidth = 0.1) +
  geom_text(aes(label = sprintf("%.2f", prob)), size = 2) +
  coord_fixed() +
scale_fill_gradientn(
  colours = c("grey85", "yellow", "red"),
  values = scales::rescale(c(0, 0.5, 1))
)+
  scale_x_continuous(
    breaks = (2 * (1:J_sub)) - 0.5,
    labels = row_col_order,
    expand = c(0, 0)
  ) +
  scale_y_reverse(
    breaks = (2 * (1:J_sub)) - 0.5,
    labels = row_col_order,
    expand = c(0, 0)
  ) +
  labs(
    x = "Models (columns, ranked by simple BT)",
    y = "Models (rows, ranked by simple BT)",
    fill = "Probability",
    title = "Multinomial model: pairwise outcome probabilities\n(top 5 and bottom 5 by Bradley–Terry ability)",
    subtitle = "Each matchup cell is a 2×2 grid: TL=left wins, TR=bottom wins, BL=tie, BR=both bad."
  ) +
  theme_minimal(base_size = 9) +
  theme(
    panel.grid = element_blank(),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    plot.title = element_text(face = "bold")
  )

```

# Bradley Terry with ties

The multinomial regression models have the advantage of being able to provide predictions for every outcome, but do not incorporate our understanding that the outcome is ordinal. For this reason, we incoprotate an extension to the Bradley-Terry model proposed by Davidson (1970) that incorporates ties through an additional parameter \(\nu > 0\), which measures the propensity for ties. For a comparison between \(i\) and \(j\), the three outcome probabilities are:

$$
P(i > j)
= \frac{r_i}{r_i + r_j + \nu \sqrt{r_i r_j}} .
$$
$$
P(j > i)
= \frac{r_j}{r_i + r_j + \nu \sqrt{r_i r_j}} .
$$
$$
P(i \sim j)
= \frac{\nu \sqrt{r_i r_j}}{r_i + r_j + \nu \sqrt{r_i r_j}} .
$$
The term \(\nu \sqrt{r_i r_j}\) increases the probability of a tie when \(r_i \approx r_j\), matching the intuition that ties occur most between evenly matched opponents. The total log-likelihood:
$$
\ell(\theta)
=
\sum_{k=1}^n 
\log P_{Y_k}(i_k, j_k \mid \theta).
$$
And we estimate the parameters via numerical optimization:
$$
\hat{\theta}
=
\arg\min_{\theta} \; -\ell(\theta).
$$


```{r, eval = F}
x_bt_tie <- x %>%
filter(winner %in% c("model_a", "model_b", "tie"),
model_a != model_b)

players <- sort(unique(c(x_bt_tie$model_a, x_bt_tie$model_b)))
J <- length(players)
```

```{r, eval = F}
bt_tie_loglik <- function(par, dat, players) {
theta <- par[1:(length(players) - 1)] 
log_nu <- par[length(players)] 
lambda <- c(0, theta) 
names(lambda) <- players
nu <- exp(log_nu) 
ll <- 0
for (k in seq_len(nrow(dat))) {
i_name <- dat$model_a[k]
j_name <- dat$model_b[k]
win <- dat$winner[k]
li <- lambda[i_name]
lj <- lambda[j_name]
ri <- exp(li)
rj <- exp(lj)

denom <- ri + rj + nu * sqrt(ri * rj)
if (win == "model_a") {
  ll <- ll + log(ri) - log(denom)
} else if (win == "model_b") {
  ll <- ll + log(rj) - log(denom)
} else if (win == "tie") {
  ll <- ll + log(nu * sqrt(ri * rj)) - log(denom)
}
}
-ll
}
```


```{r, eval = F}
bt_trace <- list(iter = 0, values = numeric()) 

bt_tie_loglik_traced <- function(par, dat, players) {
val <- bt_tie_loglik(par, dat, players)

bt_trace$iter <- bt_trace$iter + 1
bt_trace$values[bt_trace$iter] <- val

#cat("Iter:", bt_trace$iter, " Neg log-lik:", val, "\n")
flush.console()

return(val)
}

init_par <- c(rep(0, J - 1), 0)

fit_bt_tie <- optim(
par = init_par,
fn = bt_tie_loglik_traced,
dat = x_bt_tie,
players = players,
method = "BFGS",
hessian = FALSE,
control = list(reltol = 1e-4, trace = 1) 
)

fit_bt_tie$convergence
```

```{r, eval =F}
theta_hat <- fit_bt_tie$par[1:(J - 1)]
log_nu_hat <- fit_bt_tie$par[J]

abilities_tie <- c(0, theta_hat)
names(abilities_tie) <- players
nu_hat <- exp(log_nu_hat)

leaderboard_tie <- tibble(
model = players,
ability = abilities_tie
) %>%
arrange(desc(ability)) %>%
mutate(rank = row_number()) %>%
select(rank, model, ability)

print(leaderboard_tie, n = 20)
```

```{r, eval = F }
nd_all <- expand.grid(
player1 = players,
player2 = players,
KEEP.OUT.ATTRS = FALSE,
stringsAsFactors = FALSE
) %>%
filter(player1 != player2)

matchups_compare <- nd_all %>%
rowwise() %>%
mutate(
eta_bt = abilities[player1] - abilities[player2],
p_bt_player1_win = plogis(eta_bt),
p_bt_player2_win = 1 - p_bt_player1_win,

lam1_tie = abilities_tie[player1],
lam2_tie = abilities_tie[player2],
r1_tie   = exp(lam1_tie),
r2_tie   = exp(lam2_tie),

denom_tie = r1_tie + r2_tie + nu_hat * sqrt(r1_tie * r2_tie),

p_tie_player1_win = r1_tie / denom_tie,
p_tie_player2_win = r2_tie / denom_tie,
p_tie             = nu_hat * sqrt(r1_tie * r2_tie) / denom_tie

) %>%
ungroup() %>%
select(
player1, player2,
p_bt_player1_win,
p_bt_player2_win,
p_tie_player1_win,
p_tie_player2_win,
p_tie
)

matchups_compare
```


```{r, figure.width=10, fig.height=10}

players_ordered_full <- leaderboard %>%
  arrange(desc(ability)) %>%
  pull(model)

top5    <- head(players_ordered_full, 5)
bottom5 <- tail(players_ordered_full, 5)

sub_players   <- c(top5, bottom5) |> unique()
row_col_order <- players_ordered_full[players_ordered_full %in% sub_players]

pair_grid_tie <- expand.grid(
  row_model = row_col_order,
  col_model = row_col_order,
  stringsAsFactors = FALSE,
  KEEP.OUT.ATTRS = FALSE
) %>%
  filter(row_model != col_model) %>%
  left_join(
    matchups_compare,
    by = c("row_model" = "player1", "col_model" = "player2")
  )

big_grid_tie <- pair_grid_tie %>%
  mutate(
    p_left_win = p_tie_player1_win,
    p_top_win  = p_tie_player2_win,
    p_tie_only = p_tie,
    p_both_lose = 0
  ) %>%
  pivot_longer(
    cols = c(p_left_win, p_top_win, p_tie_only, p_both_lose),
    names_to = "outcome",
    values_to = "prob"
  ) %>%
  mutate(
    sub_row = case_when(
      outcome %in% c("p_left_win", "p_top_win") ~ 1L,
      TRUE                                      ~ 2L
    ),
    sub_col = case_when(
      outcome %in% c("p_left_win", "p_tie_only") ~ 1L,
      TRUE                                       ~ 2L
    ),
    row_idx = match(row_model, row_col_order),
    col_idx = match(col_model, row_col_order),
    x = (col_idx - 1) * 2 + sub_col,
    y = (row_idx - 1) * 2 + sub_row
  )

J_sub <- length(row_col_order)

ggplot(big_grid_tie, aes(x = x, y = y, fill = prob)) +
  geom_tile(color = "black", linewidth = 0.4) +
  geom_text(aes(label = sprintf("%.2f", prob)), size = 2) +
  coord_fixed() +
  scale_fill_gradientn(
    colours = c("grey85", "yellow", "red"),
    values = scales::rescale(c(0, 0.5, 1))
  ) +
  scale_x_continuous(
    breaks = (2 * (1:J_sub)) - 0.5,
    labels = row_col_order,
    expand = c(0, 0)
  ) +
  scale_y_reverse(
    breaks = (2 * (1:J_sub)) - 0.5,
    labels = row_col_order,
    expand = c(0, 0)
  ) +
  labs(
    x = "Models (columns, ranked by simple BT)",
    y = "Models (rows, ranked by simple BT)",
    fill = "Probability",
    title = "Davidson Bradley–Terry with ties (top 5 and bottom 5)",
    subtitle = "Each matchup cell is a 2×2 grid: TL=left wins, TR=top wins, BL=tie, BR=both lose (0 here)."
  ) +
  theme_minimal(base_size = 9) +
  theme(
    panel.grid = element_blank(),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    plot.title = element_text(face = "bold")
  )

```


## Enchanced BT Draw Model with Both Lose Term

```{r, eval = F}
x_bt_tie <- x %>%
filter(
winner %in% c("model_a", "model_b", "tie", "both_bad"),
model_a != model_b
)

players <- sort(unique(c(x_bt_tie$model_a, x_bt_tie$model_b)))
J <- length(players)

```

```{r, eval = F}
bt_tie_loglik <- function(par, dat, players) {
  theta <- par[1:(length(players) - 1)] 
log_nu <- par[length(players)] 
log_gamma <- par[length(players) + 1] 

lambda <- c(0, theta) 
names(lambda) <- players

nu <- exp(log_nu)
gamma <- exp(log_gamma) 

ll <- 0
for (k in seq_len(nrow(dat))) {
i_name <- dat$model_a[k]
j_name <- dat$model_b[k]
win <- dat$winner[k]

li <- lambda[i_name]
lj <- lambda[j_name]
ri <- exp(li)
rj <- exp(lj)

w_iwin   <- ri
w_jwin   <- rj
w_tie    <- nu * sqrt(ri * rj)
w_bothbad <- gamma / (ri + rj)

denom <- w_iwin + w_jwin + w_tie + w_bothbad

if (win == "model_a") {
  ll <- ll + log(w_iwin)   - log(denom)
} else if (win == "model_b") {
  ll <- ll + log(w_jwin)   - log(denom)
} else if (win == "tie") {
  ll <- ll + log(w_tie)    - log(denom)
} else if (win == "both_bad") {
  ll <- ll + log(w_bothbad) - log(denom)
}

}
-ll
}
```

```{r, eval = F}
bt_trace <- list(iter = 0, values = numeric())

bt_tie_loglik_traced <- function(par, dat, players) {
val <- bt_tie_loglik(par, dat, players)

bt_trace$iter <- bt_trace$iter + 1
bt_trace$values[bt_trace$iter] <- val

flush.console()
return(val)
}

init_par <- c(rep(0, J - 1), 0, 0)

fit_bt_tie <- optim(
par = init_par,
fn = bt_tie_loglik_traced,
dat = x_bt_tie,
players = players,
method = "BFGS",
hessian = FALSE,
control = list(reltol = 1e-4, trace = 1)
)

fit_bt_tie$convergence
```
```{r, eval = F}
# Extract MLEs from optim fit
theta_hat      <- fit_bt_tie$par[1:(J - 1)]
log_nu_hat     <- fit_bt_tie$par[J]
log_gamma_hat  <- fit_bt_tie$par[J + 1]

abilities_tie <- c(0, theta_hat)      # lambda_1 = 0 reference
names(abilities_tie) <- players

nu_hat    <- exp(log_nu_hat)
gamma_hat <- exp(log_gamma_hat)

# All ordered pairs i != j
all_pairs <- expand.grid(
  player1 = players,
  player2 = players,
  KEEP.OUT.ATTRS = FALSE,
  stringsAsFactors = FALSE
) %>%
  dplyr::filter(player1 != player2)

# Predicted probabilities for each outcome
matchups_enhanced <- all_pairs %>%
  dplyr::rowwise() %>%
  dplyr::mutate(
    lambda1 = abilities_tie[player1],
    lambda2 = abilities_tie[player2],
    r1      = exp(lambda1),
    r2      = exp(lambda2),

    w_iwin    = r1,
    w_jwin    = r2,
    w_tie     = nu_hat * sqrt(r1 * r2),
    w_bothbad = gamma_hat / (r1 + r2),

    denom = w_iwin + w_jwin + w_tie + w_bothbad,

    p_player1_win = w_iwin    / denom,
    p_player2_win = w_jwin    / denom,
    p_tie         = w_tie     / denom,
    p_both_bad    = w_bothbad / denom
  ) %>%
  dplyr::ungroup() %>%
  dplyr::select(
    player1, player2,
    p_player1_win, p_player2_win,
    p_tie, p_both_bad
  )

matchups_enhanced

```
