---
title: "Final Report"
author: "Ivan Sinyavin"
date: "2025-11-13"
output: pdf_document
---

```{r}

library(arrow)

files <- c(
  "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00000-of-00007.parquet",
  "/Users/ivansinyavin/Documents/Case Studies/Week 5/train-00001-of-00007.parquet"
  #"train-00002-of-00007.parquet",
 # "train-00003-of-00007.parquet",
  #"train-00004-of-00007.parquet",
 # "train-00005-of-00007.parquet",
  #"train-00006-of-00007.parquet"
)
x <- lapply(files, read_parquet) %>%
  bind_rows()
x <- as.data.frame(x[, c("id", "model_a", "model_b",
                         "winner", "category_tag")])
dim(x)
head(x[, 1:4])
saveRDS(x, file = 'chatbot.data.rds')
rm(list = ls())
x <- readRDS(file = 'chatbot.data.rds')
dim(x)
head(x[, 1:4])
```
```{r}
View(x)
```


# Simple Win/Loss Bradley Terry Model

We start simple. Only looking at win, loss outcomes, we fit a simple Bradley Terry model, which assigns each model $j$ an underlying ability parameter $\lambda_j$. When two models $i$ and $j$ are compared, the model assumes

$$
P(i \text{ beats } j)
=
\frac{\exp(\lambda_i)}{\exp(\lambda_i) + \exp(\lambda_j)}
=
\operatorname{logit}^{-1}(\lambda_i - \lambda_j).
$$
So this outcome is entirely governed entirely by ability differences. A higher $\lambda_i$ makes 
model $i$ more likely to win against any opponent. After constructing the design matrix $X_{\text{reduced}}$, we estimate the ability parameters via a binomial, where the outcome is modeled as $y_i \sim \text{Bernoulli}(p_i)$ where $\text{logit}(p_i) = X_{i} \, \beta.$ The estimated coefficients $\hat\beta$ are the abilities: $\hat\lambda_1 = 0,$ $\hat\lambda_j = \hat\beta_{j-1}$.


```{r}
x_bt <- x %>%
  filter(winner %in% c("model_a", "model_b"), model_a != model_b) %>%
  mutate(y = ifelse(winner == "model_a", 1, 0))  

players <- sort(unique(c(x_bt$model_a, x_bt$model_b)))
J <- length(players)
X <- matrix(0, nrow = nrow(x_bt), ncol = J,
            dimnames = list(NULL, players))
for (i in seq_len(nrow(x_bt))) {
  p1 <- x_bt$model_a[i]; p2 <- x_bt$model_b[i]; X[i, p1] <- 1; X[i, p2] <- -1
}
X_reduced <- X[, -1, drop = FALSE]
colnames(X_reduced) <- paste0("abil_", players[-1])
bt_df <- cbind(y = x_bt$y, as.data.frame(X_reduced))
bt_glm <- glm(y ~ . - 1, data = bt_df, family = binomial())
summary(bt_glm)

```

We assemble a table containing each modelâ€™s estimated ability, its standard error, and 
its confidence interval. The models are sorted by decreasing ability, which serves a rank. This produces the final Bradley--Terry leaderboard.

```{r}
beta_hat <- coef(bt_glm)               
abilities <- c(0, unname(beta_hat))     
names(abilities) <- players

V_beta <- vcov(bt_glm)

V_full <- matrix(0, nrow = J, ncol = J)
V_full[-1, -1] <- V_beta
colnames(V_full) <- rownames(V_full) <- players

se_abilities <- sqrt(diag(V_full))
z_crit <- 1.96

leaderboard <- tibble(model   = players, ability = abilities, `s.e.` = se_abilities,
  lwr = ability - z_crit * `s.e.`, upr = ability + z_crit * `s.e.`
) %>%
  arrange(desc(ability)) %>%
  mutate(rank = row_number()) %>%
  select(rank, model, ability, `s.e.`, lwr, upr)

print(leaderboard, n = 20)

```

```{r}
nd_all <- expand.grid(
  player1 = players, player2 = players, KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE
) %>% filter(player1 != player2)

matchups_ordered <- nd_all %>%
  rowwise() %>% mutate(
    eta = abilities[player1] - abilities[player2], p_player1_wins = plogis(eta)
  ) %>% ungroup() %>% select(player1, player2, p_player1_wins)

```

# Multinomial Regression Model 

We treat each possible outcome of a matchup---$A$ win, $B$ win, tie, or both\_bad---as its own
binary event. For each outcome $k \in \{\text{A},\text{B},\text{tie},\text{bad}\}$ we fit a logistic model
$$
\text{logit}\big( P(y_k = 1 \mid \text{models } i,j) \big)
= \beta^{(k)}_0 + \beta^{(k)}_i - \beta^{(k)}_j.
$$
Each set of parameters $\beta^{(k)}$ describes how strong each model is with respect 
to outcome $k$. For example, large $\beta^{(A)}_i$ means model $i$ tends to produce $A$ wins, 
large $\beta^{(\text{tie})}_i$ means model $i$ tends to generate ties, and so on.

When we pair two models $(i,j)$, each logistic regression produces a linear predictor
$$
\eta_k = \widehat{\beta}^{(k)}_0 + \widehat{\beta}^{(k)}_i - \widehat{\beta}^{(k)}_j,
\qquad k \in \{\text{A},\text{B},\text{tie},\text{bad}\}.
$$

To convert these four logits into a valid probability distribution over outcomes,
we exponentiate and normalize:
$$
p_k = \frac{e^{\eta_k}}
           {e^{\eta_A} + e^{\eta_B} + e^{\eta_{\rm tie}} + e^{\eta_{\rm bad}}},
\qquad k \in \{\text{A},\text{B},\text{tie},\text{bad}\}.
$$

These probabilities satisfy $p_A + p_B + p_{\rm tie} + p_{\rm bad} = 1,$ so for every ordered matchup $(i,j)$ the model returns a full probability distribution over the four possible outcomes.


```{r}
x_mn <- x %>%
  filter(model_a != model_b) %>%
  mutate(
    outcome = case_when(winner == "model_a" ~ "A_win", winner == "model_b" ~ "B_win", winner == "tie" ~ "tie", winner == "both_bad" ~ "both_bad")
  ) %>%
  filter(!is.na(outcome))

players <- sort(unique(c(x_mn$model_a, x_mn$model_b)))

x_mn <- x_mn %>%
  mutate(player1 = factor(model_a, levels = players), player2 = factor(model_b, levels = players))

X1 <- model.matrix(~ player1 - 1, data = x_mn)
X2 <- model.matrix(~ player2 - 1, data = x_mn)
Z  <- X1 - X2

Z  <- Z[, -1, drop = FALSE]
colnames(Z) <- paste0("theta_", players[-1])

df <- as.data.frame(Z)
df$outcome <- factor(df$outcome <- x_mn$outcome, levels = c("A_win", "B_win", "tie", "both_bad"))

y_A    <- as.integer(df$outcome == "A_win")
y_B    <- as.integer(df$outcome == "B_win")
y_Tie  <- as.integer(df$outcome == "tie")
y_BBad <- as.integer(df$outcome == "both_bad")

predictors_df <- transform(df, outcome = NULL)

fit_A    <- glm(y_A ~ ., data = predictors_df, family = binomial())
fit_B    <- glm(y_B ~ ., data = predictors_df, family = binomial())
fit_Tie  <- glm(y_Tie ~ ., data = predictors_df, family = binomial())
fit_BBad <- glm(y_BBad ~ ., data = predictors_df, family = binomial())

#summary(fit_A); summary(fit_B); summary(fit_Tie); summary(fit_BBad)

make_Z_row <- function(p1, p2, players) {
  v1 <- rep(0, length(players)); v2 <- rep(0, length(players))
  names(v1) <- names(v2) <- players
  v1[p1] <-  1
  v2[p2] <- -1
  z <- v1 + v2           
  z_reduced <- z[-1]    
  names(z_reduced) <- paste0("theta_", players[-1])
  as.data.frame(t(z_reduced))
}

all_pairs <- expand.grid(player1 = players, player2 = players,
                         stringsAsFactors = FALSE) %>%filter(player1 != player2)

Z_new <- do.call(rbind, lapply(seq_len(nrow(all_pairs)), function(k) {
                   make_Z_row(all_pairs$player1[k], all_pairs$player2[k], players)}))

eta_A_new    <- predict(fit_A,    newdata = Z_new, type = "link")
eta_B_new    <- predict(fit_B,    newdata = Z_new, type = "link")
eta_Tie_new  <- predict(fit_Tie,  newdata = Z_new, type = "link")
eta_BBad_new <- predict(fit_BBad, newdata = Z_new, type = "link")

denom <- exp(eta_A_new) + exp(eta_B_new) + exp(eta_Tie_new) + exp(eta_BBad_new)

p_A_new <- exp(eta_A_new) / denom
p_B_new <- exp(eta_B_new) / denom
p_Tie_new  <- exp(eta_Tie_new) / denom
p_BBad_new <- exp(eta_BBad_new)/ denom

```


```{r}
matchups_full <- tibble(
  player1 = all_pairs$player1,
  player2 = all_pairs$player2,
  p_A_win    = p_A_new,
  p_B_win    = p_B_new,
  p_Tie      = p_Tie_new,
  p_BothBad  = p_BBad_new
)

matchups_full
```


# BT with ties

```{r}
x_bt_tie <- x %>%
filter(winner %in% c("model_a", "model_b", "tie"),
model_a != model_b)

players <- sort(unique(c(x_bt_tie$model_a, x_bt_tie$model_b)))
J <- length(players)
```

```{r}
bt_tie_loglik <- function(par, dat, players) {
theta <- par[1:(length(players) - 1)] 
log_nu <- par[length(players)] 
lambda <- c(0, theta) 
names(lambda) <- players
nu <- exp(log_nu) 
ll <- 0
for (k in seq_len(nrow(dat))) {
i_name <- dat$model_a[k]
j_name <- dat$model_b[k]
win <- dat$winner[k]
li <- lambda[i_name]
lj <- lambda[j_name]
ri <- exp(li)
rj <- exp(lj)

denom <- ri + rj + nu * sqrt(ri * rj)
if (win == "model_a") {
  ll <- ll + log(ri) - log(denom)
} else if (win == "model_b") {
  ll <- ll + log(rj) - log(denom)
} else if (win == "tie") {
  ll <- ll + log(nu * sqrt(ri * rj)) - log(denom)
}
}
-ll
}
```


```{r}
bt_trace <- list(iter = 0, values = numeric()) 

bt_tie_loglik_traced <- function(par, dat, players) {
val <- bt_tie_loglik(par, dat, players)

bt_trace$iter <- bt_trace$iter + 1
bt_trace$values[bt_trace$iter] <- val

#cat("Iter:", bt_trace$iter, " Neg log-lik:", val, "\n")
flush.console()

return(val)
}

init_par <- c(rep(0, J - 1), 0)

fit_bt_tie <- optim(
par = init_par,
fn = bt_tie_loglik_traced,
dat = x_bt_tie,
players = players,
method = "BFGS",
hessian = TRUE,
control = list(reltol = 1e-3, trace = 1) 
)

fit_bt_tie$convergence
```

```{r}
theta_hat <- fit_bt_tie$par[1:(J - 1)]
log_nu_hat <- fit_bt_tie$par[J]

abilities_tie <- c(0, theta_hat)
names(abilities_tie) <- players
nu_hat <- exp(log_nu_hat)
H_par <- fit_bt_tie$hessian
V_par <- solve(H_par)
V_theta <- V_par[1:(J - 1), 1:(J - 1), drop = FALSE]

V_full_abilities <- matrix(0, nrow = J, ncol = J)
V_full_abilities[-1, -1] <- V_theta
colnames(V_full_abilities) <- rownames(V_full_abilities) <- players

se_abilities_tie <- sqrt(diag(V_full_abilities))
z_crit <- 1.96

leaderboard_tie <- tibble(
model = players,
ability = abilities_tie,
s.e. = se_abilities_tie,
lwr = ability - z_crit * s.e.,
upr = ability + z_crit * s.e.
) %>%
arrange(desc(ability)) %>%
mutate(rank = row_number()) %>%
select(rank, model, ability, s.e., lwr, upr)

print(leaderboard_tie, n = 20)
```

