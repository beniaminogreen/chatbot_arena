---
output : pdf_document
---

# Measurement-Error Models

In this section, consider two of measurement-error models, which aim to provide
accurate predictions for all four outcomes while respecting the ordered nature
of the outcome for games that do not end in a 'both-bad' result.

In these models, we assume that the "A win", "B win", and "tie" outcomes can be
well-described by an ordered logistic regression model. This kind of model
performs well when predicting the frequency of these three outcomes among games
that did not end in a 'both bad' outcome.

$$
Y_i 
$$

However, across both models, we assume that each model $i$ has an indepent
chance of a 'faliure', which can interfere with our observation. Specifically,
for each game $k$, each model flips a baised coin with probaility of heads $\rho_i$
to get an indicator variable $X_(i,k)$, which determines how their outcome is
observed.

In model 1, we assume that a player failing means they are inelligble to win.
Thus, if neither model fails, then the observed outcome is $Y_i$. If either
fails and the other does not, then their opponent wins. Finally, if both models
fail, then the 'both-bad' outcome is observed. This logic is summarized below:

$$
Y_\text{observed} = 
\begin{cases}
Y_i \quad \quad  (X_i != 1) \& (X_i' != 1) \\
\text{A wins} \quad  \quad (X_i != 1) \& (X_i' = 1) \\
\text{B wins} \quad  \quad (X_i = 1) \& (X_i' != 1) \\
\text{both bad} \quad  \quad (X_i = 1) \& (X_i' = 1)\\
\end{cases}
$$

In model 2, we keep the failure probabilities, but assume that a failure from
either model simply derails the competition and forces a 'both-bad' outcome.

$$
Y_\text{observed} = 
\begin{cases}
Y_i \quad \quad  (X_i != 1) \& (X_i' != 1) \\
\text{both bad} \quad  \quad \text{otherwise}
\end{cases}
$$


